<!DOCTYPE html><html>  <head>    <title>Vectorizing World Buildings: Planar Graph Reconstruction by Primitive Detection and Relationship Inference</title>    <link rel="stylesheet" href="../assets/css/project.css">  </head>  <body>    <div class="content project_title">      <h1>Vectorizing World Buildings: Planar Graph Reconstruction by Primitive Detection and Relationship Inference</h1>	  <h2 class="project-tagline"><a class="site-link" href="http://www.sfu.ca/~nnauata/">Nelson Nauata</a> and 								  <a class="site-link" href="https://www.cs.sfu.ca/~furukawa/">Yasutaka Furukawa</a></h2>	  <!--text font-size=10px>(*authors contributed equally)</text-->    </div>    <div class="content project_headline">      <div class="img">        <img class="img_teaser" src="teaser.jpg" alt="Teaser">      </div>      <div class="text">        <p>Figure 1.  The paper takes a RGB image, detects three geometric primitives (i.e., corners, edges, and regions), infers their relationships(i.e., corner-to-edge and region-to-region), and fuses the information via Integer Programming to reconstruct a planar graph.</p>      </div>      <hr />    </div>    <div class="content">      <div class="text">        <h3>Abstract</h3>        <p>This paper tackles a 2D architecture vectorization problem, whose task is to infer an outdoor building architecture as a 2D planar graph from a single RGB image. We provide a new benchmark with ground-truth annotations for 2,001 complex buildings across the cities of Atlanta, Paris, and Las Vegas. We also propose a novel algorithm utilizing 1) convolutional neural networks (CNNs) that detects geometric primitives and infers their relationships and 2) an integer programming (IP) that assembles the information into a 2D planar graph. While being a trivial task for human vision, the inference of a graph structure with an arbitrary topology is still an open problem for computer vision. Qualitative and quantitative evaluations demonstrate that our algorithm makes significant improvements over the current state-of-the-art, towards an intelligent system at the level of human perception. We will share code and data. </p>      </div>	  <hr />	      </div>    <div class="content">      <div class="text">        <h3>Paper</h3>      </div>      <div class="img">		<img class="img_teaser" src="paper.jpg">      </div>      <div class="center_text">	     <span class="link"><a href="https://arxiv.org/abs/1912.05135">[Arxiv]</a></span>	     <span class="link"><a href="./buildings_suppl.pdf">[Supp.]</a></span>	     <span class="link"><a href="./bib.txt">[Bibtex]</a></span>	  </div>	  <hr />	</div>		<div class="content">		<div class="text">			<h3>Code/Data</h3>		</div>		<p>Check the code and data on this <a href="https://github.com/ennauata/buildings2vec">repo</a>.</p>		<hr />	</div>		<div class="content bottom_block">		<div class="text">			<h3>Acknowledgement</h3>		</div>		<p>This research is partially supported by NSERC Discovery Grants, NSERC Discovery Grants Accelerator Supplements, and DND/NSERC Discovery Grant 		Supplement. This research is also supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior / Interior Business Center 		(DOI/IBC) contract number D17PC00288. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright 		annotation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies 		or endorsements, either expressed or implied, of IARPA, DOI/IBC, or the U.S. Government.</p>		<hr />	</div>      </body></html>