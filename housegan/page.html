<!DOCTYPE html><html>  <head>    <title>House-GAN: Relational Generative Adversarial Networks for Graph-constrained House Layout Generation</title>    <link rel="stylesheet" href="../assets/css/project.css">  </head>  <body>    <div class="content project_title">      <h1>House-GAN: Relational Generative Adversarial Networks for Graph-constrained House Layout Generation</h1>	  <h2 class="project-tagline"><a class="site-link" href="http://www.sfu.ca/~nnauata/">Nelson Nauata</a> and 								  <a class="site-link" href="https://www.cs.sfu.ca/~furukawa/">Yasutaka Furukawa</a></h2>	  <!--text font-size=10px>(*authors contributed equally)</text-->    </div>    <div class="content project_headline">      <div class="img">        <img class="img_teaser" src="teaser.jpg" alt="Teaser">      </div>      <div class="text">        <p>Figure 1.  The paper takes a RGB image, detects three geometric primitives (i.e., corners, edges, and regions), classifiers their relationships(i.e., corner-to-edge and region-to-region), and fuses the information via Integer Programming to reconstruct a planar graph.</p>      </div>      <hr />    </div>    <div class="content">      <div class="text">        <h3>Abstract</h3>        	<p>This paper proposes a novel graph-constrained generative adversarial network, whose generator and discriminator are built upon relational architecture. The main idea is to encode the constraint into the graph structure of its relational networks. We have demonstrated the proposed architecture for a new house layout generation problem, whose task is to take an architectural constraint as a graph (i.e., the number and types of rooms with their spatial adjacency) and produce a set of axis-aligned bounding boxes of rooms. We measure the quality of generated house layouts with the three metrics: the realism, the diversity, and the compatibility with the input graph constraint. Our qualitative and quantitative evaluations over 117,000 real floorplan images demonstrate that the proposed approach outperforms existing methods and baselines. We will publicly share all our code and data.</p>      </div>	  <hr />	      </div>    <div class="content">      <div class="text">        <h3>Paper</h3>      </div>      <div class="img">		<img class="img_teaser" src="paper.jpg">      </div>      <div class="center_text">	     <span class="link"><a href="https://arxiv.org/abs/2003.06988">[Arxiv]</a></span>	     <span class="link"><a href="./housegan_suppl.pdf">[Supp.]</a></span>	     <span class="link"><a href="./bib.txt">[Bibtex]</a></span>	  </div>	  <hr />	</div>		<div class="content">		<div class="text">			<h3>Code/Data</h3>		</div>		<p>Check the code and data on this <a href="https://github.com/ennauata/housegan">repo</a>.</p>		<hr />	</div>		<div class="content bottom_block">		<div class="text">			<h3>Acknowledgement</h3>		</div>		<p>This research is partially supported by NSERC Discovery Grants, NSERC Discovery Grants Accelerator Supplements, and DND/NSERC Discovery Grant 		Supplement. This research is also supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior / Interior Business Center 		(DOI/IBC) contract number D17PC00288. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright 		annotation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies 		or endorsements, either expressed or implied, of IARPA, DOI/IBC, or the U.S. Government.</p>		<hr />	</div>      </body></html>