<!DOCTYPE html>
<html>
  <head>
    <title>DORF: Decomposing Object Radiance Field </br>from Supporting Planes</title>
    <link rel="stylesheet" href="../assets/css/project.css">
  </head>

  <body>
    <div class="content project_title">
      <h1>DORF: Decomposing Object Radiance Field from Supporting Planes</h1>
	  <h2 class="project-tagline"><a class="site-link">Nelson Nauata</a>, 
	  			      <a class="site-link">Chen Liu</a>,
	  			      <a class="site-link">Zhaoyang Lv</a>  
	  			
	  <!--text font-size=10px>(*authors contributed equally)</text-->
    </div>

    <div class="content project_headline">
      <div class="img">
        <img class="img_teaser" src="teaser.jpg" alt="Teaser">
      </div>
      <div class="text">
        <p>Figure 1. House-GAN is a novel graph-constrained house layout generator, built upon a relational generative adversarial network. The bubble diagram (graph) is given as an input for automatically generating multiple house layout options.</p>
      </div>
      <hr />
    </div>

    <div class="content">
      <div class="text">
        <h3>Abstract</h3>
        	<p>We propose a novel self-supervised neural reconstruction method that can reconstruct and segment 3D objects at high-quality using localized multi-view images. By assuming objects usually sitting on one supporting plane, we represent a 3D scene as one major supporting plane with multiple objects on top, with each entity as a neural radiance field parameterized by a coordinate-based MLP. We jointly reconstruct the 3D objects, the planar structure, and the 3D decomposition via multi-pass differentiable neural radiance field rendering using only images as input. In contrast to the traditional semantic-based 3D object localization and reconstruction methods, our method is completely taxonomy free and can achieve accurate 3D segmentation for a wide variety of opaque objects. We demonstrate that our method can achieve high-quality view-consistent rendering and object segmentation for a wide range of objects in CO3D dataset without using any provided masks. Our method works equally well for objects which can not be detected and localized by semantic-based methods. With the accurate geometry, appearance modeling and decomposition, we can further enable 3D object discovery and scene editing applications.</p>
      </div>
	  <hr />
	  
    </div>

    <div class="content">
      <div class="text">
        <h3>Paper</h3>
      </div>
      <div class="img">
		<img class="img_teaser" src="paper.jpg">
      </div>
      <div class="center_text">
	     <span class="link"><a href="https://arxiv.org/abs/2003.06988">[Arxiv]</a></span>
	     <span class="link"><a href="./DORF_supp.pdf">[Supp.]</a></span>
<!-- 	     <span class="link"><a href="./bib.txt">[Bibtex]</a></span> -->
	     <span class="link"><a href="https://papers.eccv2020.eu/paper/677/">[Video presentation (ECCV'20)]</a></span>
	  </div>
	  <hr />
	</div>
	
	<div class="content">
<!-- 		<div class="text">
			<h3>Code/Data</h3>
		</div> -->
<!-- 		 <p>Check the code and data on this <a href="https://github.com/ennauata/housegan">repo</a>.</p> -->
		<hr />
	</div>
	
	<div class="content bottom_block">
		<div class="text">
			<h3>Acknowledgement</h3>
		</div>
		<p>This research is partially supported by NSERC Discovery Grants, NSERC Discovery Grants Accelerator Supplements, and DND/NSERC Discovery Grant Supplement. We would like to thank architects and students for participating in our user study.</p>
		<hr />
	</div>
    
  </body>
</html>
